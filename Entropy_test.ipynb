{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-27T21:24:04.504176Z",
     "start_time": "2024-11-27T21:23:17.509778Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\"\n",
    "import keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from sklearn.metrics.cluster import entropy\n",
    "from tf_keras import layers,losses,optimizers,Sequential\n",
    "from tf_keras.models import Model\n",
    "from tf_keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D,Input\n",
    "from tf_keras.applications import VGG16\n",
    "from tf_keras import datasets,models\n",
    "import importlib"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T21:24:04.515921Z",
     "start_time": "2024-11-27T21:24:04.511405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "id": "ac5bc649c1bea00",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T21:24:06.547166Z",
     "start_time": "2024-11-27T21:24:04.726133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from importing_dataset import load_dataset\n",
    "import Entropy\n",
    "importlib.reload(Entropy)\n",
    "train_examples, validation_examples, num_examples, num_classes, class_names = load_dataset('horses_or_humans', 70)"
   ],
   "id": "3dfca37d679c6ef0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from C:\\Users\\neyen\\tensorflow_datasets\\horses_or_humans\\3.0.0\n",
      "INFO:absl:Creating a tf.data.Dataset reading 2 files located in folders: C:\\Users\\neyen\\tensorflow_datasets\\horses_or_humans\\3.0.0.\n",
      "INFO:absl:Creating a tf.data.Dataset reading 1 files located in folders: C:\\Users\\neyen\\tensorflow_datasets\\horses_or_humans\\3.0.0.\n",
      "INFO:absl:Constructing tf.data.Dataset horses_or_humans for split ('train[:70%]', 'train[70%:]'), from C:\\Users\\neyen\\tensorflow_datasets\\horses_or_humans\\3.0.0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T21:24:06.635512Z",
     "start_time": "2024-11-27T21:24:06.571775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from reformatting import reformat_image\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "train_batches = train_examples.cache().shuffle(num_examples//4).map(reformat_image).batch(BATCH_SIZE).prefetch(1)\n",
    "validation_batches = validation_examples.map(reformat_image).batch(BATCH_SIZE).prefetch(1)\n",
    "train_batches"
   ],
   "id": "cdc250b3c14c9cb1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T21:26:37.060261Z",
     "start_time": "2024-11-27T21:26:35.687104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from tf_keras import backend as K\n",
    "# Assurez-vous que l'entrée est un KerasTensor\n",
    "input_layer = K.placeholder(shape=(None, 224, 224, 3), dtype='float32')\n",
    "\n",
    "\n",
    "# Bloc 1\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(input_layer)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "# Bloc 2\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "# Bloc 3\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "# Bloc 4\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "# Bloc 5\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "# Ajouter des couches supplémentaires\n",
    "x = layers.GlobalMaxPooling2D(name=\"global_max_pool\")(x)\n",
    "x = layers.Dropout(0.3, name=\"dropout\")(x)\n",
    "outputs = layers.Dense(2, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "# Construire le modèle\n",
    "model = Model(input_layer, outputs, name=\"custom_vgg16.keras\")\n",
    "model.summary()\n",
    "\n",
    "# Charger les poids de VGG16\n",
    "vgg16_base = VGG16(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "\n",
    "from test_surgeon import Surgeon\n",
    "# Appliquer les poids pour chaque couche manuellement\n",
    "for layer, pretrained_layer in zip(model.layers, vgg16_base.layers):\n",
    "    if isinstance(layer, layers.Conv2D):\n",
    "        layer.set_weights(pretrained_layer.get_weights())\n",
    "\n",
    "input_layer = model.input  # L'entrée du modèle\n",
    "layer_0 = model.layers[1]  # Index 1 car la première couche est 'input_40'\n",
    "surgeon = Surgeon(model)\n",
    "\n",
    "# Si la couche 0 est une Conv2D, supprimer les canaux\n",
    "if isinstance(layer_0, layers.Conv2D):\n",
    "    # Surgeon pour supprimer les canaux\n",
    "    surgeon.add_job('delete_channels', layer_0, channels=[0, 1, 2])\n",
    "    pruned_model = surgeon.operate()\n",
    "\n",
    "    # Redéfinir les entrées et sorties du modèle après modification\n",
    "    pruned_model = Model(inputs=input_layer, outputs=pruned_model.output)\n",
    "\n",
    "    # Redéfinir les entrées du modèle (pour qu'elles soient un KerasTensor valide)\n",
    "    pruned_model.build(input_shape=(None, 224, 224, 3))\n",
    "\n",
    "    # Recompiler le modèle pour qu'il soit prêt à l'entraînement ou à la prédiction\n",
    "    pruned_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"La couche spécifiée n'est pas une couche Conv2D.\")\n",
    "\n",
    "pruned_model.summary()\n"
   ],
   "id": "861e115df888413e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_vgg16.keras\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_max_pool (GlobalMax  (None, 512)               0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14715714 (56.14 MB)\n",
      "Trainable params: 14715714 (56.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Deleting 3/64 channels from layer: block1_conv1\n",
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\optimizers\\__init__.py:317: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\optimizers\\__init__.py:317: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 61)      1708      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      35200     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_max_pool (GlobalMax  (None, 512)               0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14713902 (56.13 MB)\n",
      "Trainable params: 14713902 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T21:38:22.826256Z",
     "start_time": "2024-11-27T21:38:20.449638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import Entropy_Keras_Surgeon\n",
    "importlib.reload(Entropy_Keras_Surgeon)\n",
    "from Entropy_Keras_Surgeon import EntropyPruningSurgeon\n",
    "testt_model = models.load_model(\"model_experiments/custom_vgg16.keras\")\n",
    "testt_model.summary()\n",
    "pruning = EntropyPruningSurgeon(model=testt_model, threshold=0.06)\n",
    "pruningmodel = pruning.run()\n",
    "pruningmodel.summary()"
   ],
   "id": "6db2bde71aab52b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_40 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_max_pool (GlobalMax  (None, 512)               0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14715714 (56.14 MB)\n",
      "Trainable params: 1026 (4.01 KB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n",
      "Suppression complète de la couche 'block4_conv1' (tous les filtres).\n",
      "Suppression complète de la couche 'block4_conv2' (tous les filtres).\n",
      "Suppression complète de la couche 'block4_conv3' (tous les filtres).\n",
      "Suppression complète de la couche 'block5_conv1' (tous les filtres).\n",
      "Suppression complète de la couche 'block5_conv2' (tous les filtres).\n",
      "Suppression complète de la couche 'block5_conv3' (tous les filtres).\n",
      "Deleting 2/64 channels from layer: block1_conv1\n",
      "Deleting 0/64 channels from layer: block1_conv2\n",
      "Deleting 23/128 channels from layer: block2_conv1\n",
      "Deleting 2/128 channels from layer: block2_conv2\n",
      "Deleting 245/256 channels from layer: block3_conv1\n",
      "Deleting 230/256 channels from layer: block3_conv2\n",
      "Deleting 238/256 channels from layer: block3_conv3\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " input_40 (InputLayer)       multiple                  0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 62)      1736      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      35776     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 105)     60585     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 126)     119196    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  multiple                  0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 11)        12485     \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 26)        2600      \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 18)        4230      \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  multiple                  0         \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  multiple                  0         \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  multiple                  0         \n",
      "                                                                 \n",
      " global_max_pool (GlobalMax  multiple                  0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 2)                 38        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 236646 (924.40 KB)\n",
      "Trainable params: 38 (152.00 Byte)\n",
      "Non-trainable params: 236608 (924.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T02:28:58.363281Z",
     "start_time": "2024-11-27T02:28:57.148188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tf_keras import layers, Model, Input\n",
    "from tf_keras.applications import VGG16\n",
    "from tf2kerassurgeon import Surgeon\n",
    "\n",
    "# Initialisation du modèle\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "# Bloc 1\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "# Bloc 2\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "# Bloc 3\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "# Bloc 4\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "# Bloc 5\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "# Ajouter des couches supplémentaires\n",
    "x = layers.GlobalMaxPooling2D(name=\"global_max_pool\")(x)\n",
    "x = layers.Dropout(0.3, name=\"dropout\")(x)\n",
    "outputs = layers.Dense(2, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "# Construire le modèle\n",
    "model = Model(inputs, outputs, name=\"custom_vgg16.keras\")\n",
    "\n",
    "# Charger les poids de VGG16\n",
    "vgg16_base = VGG16(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "\n",
    "# Appliquer les poids pour chaque couche manuellement\n",
    "for layer, pretrained_layer in zip(model.layers, vgg16_base.layers):\n",
    "    if isinstance(layer, layers.Conv2D):\n",
    "        layer.set_weights(pretrained_layer.get_weights())\n",
    "\n",
    "# Appliquer le pruning sur la première couche de convolution\n",
    "input_layer = model.input\n",
    "layer_0 = model.layers[1]  # La première couche Conv2D dans votre modèle\n",
    "\n",
    "surgeon = Surgeon(model)\n",
    "\n",
    "# Vérifier si la couche est une Conv2D\n",
    "if isinstance(layer_0, layers.Conv2D):\n",
    "    surgeon.add_job('delete_channels', layer_0, channels=[0, 1, 2])\n",
    "    pruned_model = surgeon.operate()\n",
    "\n",
    "    # Redéfinir le modèle après pruning\n",
    "    pruned_model = Model(inputs=input_layer, outputs=pruned_model.output)\n",
    "\n",
    "    # Rebuild le modèle pour assurer que l'entrée est bien un KerasTensor\n",
    "    pruned_model.build(input_shape=(None, 224, 224, 3))\n",
    "\n",
    "    # Recompiler le modèle pour qu'il soit prêt à l'entraînement ou à la prédiction\n",
    "    pruned_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Affichage du résumé du modèle\n",
    "    pruned_model.summary()\n",
    "\n",
    "else:\n",
    "    print(\"La couche spécifiée n'est pas une couche Conv2D.\")\n"
   ],
   "id": "946c2bf689cd7a9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting 3/64 channels from layer: block1_conv1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All `inputs` values must be KerasTensors. Received: inputs=[<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_8')>] including invalid value KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\") of type <class 'tf_keras.src.engine.keras_tensor.KerasTensor'>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 61\u001B[0m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(layer_0, layers\u001B[38;5;241m.\u001B[39mConv2D):\n\u001B[0;32m     60\u001B[0m     surgeon\u001B[38;5;241m.\u001B[39madd_job(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdelete_channels\u001B[39m\u001B[38;5;124m'\u001B[39m, layer_0, channels\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m])\n\u001B[1;32m---> 61\u001B[0m     pruned_model \u001B[38;5;241m=\u001B[39m \u001B[43msurgeon\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moperate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;66;03m# Redéfinir le modèle après pruning\u001B[39;00m\n\u001B[0;32m     64\u001B[0m     pruned_model \u001B[38;5;241m=\u001B[39m Model(inputs\u001B[38;5;241m=\u001B[39minput_layer, outputs\u001B[38;5;241m=\u001B[39mpruned_model\u001B[38;5;241m.\u001B[39moutput)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf2kerassurgeon\\surgeon.py:166\u001B[0m, in \u001B[0;36mSurgeon.operate\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    164\u001B[0m     output_nodes\u001B[38;5;241m.\u001B[39mappend(get_inbound_nodes(layer)[node_index])\n\u001B[0;32m    165\u001B[0m new_outputs, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_rebuild_graph(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39minputs, output_nodes)\n\u001B[1;32m--> 166\u001B[0m new_model \u001B[38;5;241m=\u001B[39m \u001B[43mModel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_copy:\n\u001B[0;32m    169\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m utils\u001B[38;5;241m.\u001B[39mclean_copy(new_model)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\keras\\src\\utils\\tracking.py:26\u001B[0m, in \u001B[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(fn)\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m DotNotTrackScope():\n\u001B[1;32m---> 26\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\keras\\src\\models\\functional.py:119\u001B[0m, in \u001B[0;36mFunctional.__init__\u001B[1;34m(self, inputs, outputs, name, **kwargs)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m flat_inputs:\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, backend\u001B[38;5;241m.\u001B[39mKerasTensor):\n\u001B[1;32m--> 119\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    120\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll `inputs` values must be KerasTensors. Received: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    121\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minputs=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00minputs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m including invalid value \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    122\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(x)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    123\u001B[0m         )\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m flat_outputs:\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, backend\u001B[38;5;241m.\u001B[39mKerasTensor):\n",
      "\u001B[1;31mValueError\u001B[0m: All `inputs` values must be KerasTensors. Received: inputs=[<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_8')>] including invalid value KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\") of type <class 'tf_keras.src.engine.keras_tensor.KerasTensor'>"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T02:28:19.844848Z",
     "start_time": "2024-11-27T02:28:19.802538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Charger votre modèle\n",
    "importlib.reload(Entropy)\n",
    "from Entropy import EntropyPruning\n",
    "testt_model = models.load_model(\"model_experiments/custom_vgg16.keras\")\n",
    "testt_model.summary()"
   ],
   "id": "4ba92eb3e9fe6aba",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'μ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mµ\u001B[49m\u001B[38;5;66;03m# Charger votre modèle\u001B[39;00m\n\u001B[0;32m      2\u001B[0m importlib\u001B[38;5;241m.\u001B[39mreload(Entropy)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mEntropy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m EntropyPruning\n",
      "\u001B[1;31mNameError\u001B[0m: name 'μ' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d3424e5788e68c42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:40:46.160787Z",
     "start_time": "2024-11-27T00:40:44.565754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pruning = EntropyPruning(model=testt_model, threshold=0.01)\n",
    "pruned_model = pruning.prune_model(None)\n",
    "pruned_model.summary()\n",
    "\n",
    "# # Test the model\n",
    "# pruned_model.compile(\n",
    "#     optimizer = 'adam',\n",
    "#     loss = losses.SparseCategoricalCrossentropy(),\n",
    "#     metrics=['accuracy'])\n",
    "#\n",
    "# pruned_model.evaluate(validation_batches)\n"
   ],
   "id": "b58a8495f4cc4ce4",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EntropyPruning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pruning \u001B[38;5;241m=\u001B[39m \u001B[43mEntropyPruning\u001B[49m(model\u001B[38;5;241m=\u001B[39mtestt_model, threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m      2\u001B[0m pruned_model \u001B[38;5;241m=\u001B[39m pruning\u001B[38;5;241m.\u001B[39mprune_model(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m      3\u001B[0m pruned_model\u001B[38;5;241m.\u001B[39msummary()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'EntropyPruning' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T01:58:38.506707Z",
     "start_time": "2024-11-27T01:58:37.325194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tf2kerassurgeon.operations import delete_channels\n",
    "from tf2kerassurgeon import Surgeon\n",
    "\n",
    "# Création d'un modèle de test\n",
    "x = Input(shape=(224, 224, 3))\n",
    "y = layers.Conv2D(32, (3, 3), activation='relu')(x)\n",
    "y = layers.MaxPooling2D((2, 2))(y)\n",
    "y = layers.Conv2D(64, (3, 3), activation='relu')(y)\n",
    "y = layers.MaxPooling2D((2, 2))(y)\n",
    "y = layers.Conv2D(64, (3, 3), activation='relu')(y)\n",
    "y = layers.Flatten()(y)\n",
    "y = layers.Dense(64, activation='relu')(y)\n",
    "y = layers.Dense(10, activation='softmax')(y)\n",
    "\n",
    "testt_model = Model(x, y)\n",
    "\n",
    "# Vérification que la couche d'entrée est valide\n",
    "input_layer = testt_model.input  # L'entrée du modèle\n",
    "layer_0 = testt_model.layers[1]  # Index 1 car la première couche est 'input_40'\n",
    "surgeon = Surgeon(testt_model)\n",
    "\n",
    "# Si la couche 0 est une Conv2D, supprimer les canaux\n",
    "if isinstance(layer_0, layers.Conv2D):\n",
    "    # Surgeon pour supprimer les canaux\n",
    "    surgeon.add_job('delete_channels', layer_0, channels=[0, 1, 2])\n",
    "    pruned_model = surgeon.operate()\n",
    "\n",
    "    # Redéfinir les entrées et sorties du modèle après modification\n",
    "    pruned_model = Model(inputs=input_layer, outputs=pruned_model.output)\n",
    "\n",
    "    # Redéfinir les entrées du modèle (pour qu'elles soient un KerasTensor valide)\n",
    "    pruned_model.build(input_shape=(None, 224, 224, 3))\n",
    "\n",
    "    # Recompiler le modèle pour qu'il soit prêt à l'entraînement ou à la prédiction\n",
    "    pruned_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Affichage du résumé du modèle\n",
    "    pruned_model.summary()\n",
    "\n",
    "else:\n",
    "    print(\"La couche spécifiée n'est pas une couche Conv2D.\")\n",
    "\n"
   ],
   "id": "748e46e486afd10d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\backend.py:1400: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\backend.py:1400: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting 3/32 channels from layer: conv2d\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All `inputs` values must be KerasTensors. Received: inputs=[<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_1')>] including invalid value KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\") of type <class 'tf_keras.src.engine.keras_tensor.KerasTensor'>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 28\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(layer_0, layers\u001B[38;5;241m.\u001B[39mConv2D):\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;66;03m# Surgeon pour supprimer les canaux\u001B[39;00m\n\u001B[0;32m     27\u001B[0m     surgeon\u001B[38;5;241m.\u001B[39madd_job(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdelete_channels\u001B[39m\u001B[38;5;124m'\u001B[39m, layer_0, channels\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m])\n\u001B[1;32m---> 28\u001B[0m     pruned_model \u001B[38;5;241m=\u001B[39m \u001B[43msurgeon\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moperate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;66;03m# Redéfinir les entrées et sorties du modèle après modification\u001B[39;00m\n\u001B[0;32m     31\u001B[0m     pruned_model \u001B[38;5;241m=\u001B[39m Model(inputs\u001B[38;5;241m=\u001B[39minput_layer, outputs\u001B[38;5;241m=\u001B[39mpruned_model\u001B[38;5;241m.\u001B[39moutput)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf2kerassurgeon\\surgeon.py:166\u001B[0m, in \u001B[0;36mSurgeon.operate\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    164\u001B[0m     output_nodes\u001B[38;5;241m.\u001B[39mappend(get_inbound_nodes(layer)[node_index])\n\u001B[0;32m    165\u001B[0m new_outputs, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_rebuild_graph(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39minputs, output_nodes)\n\u001B[1;32m--> 166\u001B[0m new_model \u001B[38;5;241m=\u001B[39m \u001B[43mModel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_copy:\n\u001B[0;32m    169\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m utils\u001B[38;5;241m.\u001B[39mclean_copy(new_model)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\keras\\src\\utils\\tracking.py:26\u001B[0m, in \u001B[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(fn)\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m DotNotTrackScope():\n\u001B[1;32m---> 26\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\keras\\src\\models\\functional.py:119\u001B[0m, in \u001B[0;36mFunctional.__init__\u001B[1;34m(self, inputs, outputs, name, **kwargs)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m flat_inputs:\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, backend\u001B[38;5;241m.\u001B[39mKerasTensor):\n\u001B[1;32m--> 119\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    120\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll `inputs` values must be KerasTensors. Received: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    121\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minputs=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00minputs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m including invalid value \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    122\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(x)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    123\u001B[0m         )\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m flat_outputs:\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, backend\u001B[38;5;241m.\u001B[39mKerasTensor):\n",
      "\u001B[1;31mValueError\u001B[0m: All `inputs` values must be KerasTensors. Received: inputs=[<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_1')>] including invalid value KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\") of type <class 'tf_keras.src.engine.keras_tensor.KerasTensor'>"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T01:32:37.742925Z",
     "start_time": "2024-11-27T01:32:37.310827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tf_keras import Model\n",
    "from tf_keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tf2kerassurgeon.operations import delete_channels\n",
    "from tf2kerassurgeon import Surgeon\n",
    "\n",
    "# Création d'un modèle de test\n",
    "x = Input(shape=(224, 224, 3))\n",
    "y = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "y = MaxPooling2D((2, 2))(y)\n",
    "y = Conv2D(64, (3, 3), activation='relu')(y)\n",
    "\n",
    "# Ajouter une couche Dense pour la sortie\n",
    "y = Flatten()(y)\n",
    "y = Dense(64, activation='relu')(y)\n",
    "y = Dense(10, activation='softmax')(y)\n",
    "\n",
    "testt_model = Model(x, y)\n",
    "\n",
    "\n",
    "layer_0 = testt_model.layers[1]  # Index 1 car la première couche est 'input_40'\n",
    "# Vérification du type d'entrée\n",
    "print(type(testt_model.input))  # Devrait afficher <class 'tensorflow.python.keras.engine.keras_tensor.KerasTensor'>\n",
    "\n",
    "# Surgeon pour supprimer les canaux\n",
    "surgeon = Surgeon(testt_model)\n",
    "surgeon.add_job('delete_channels', layer_0, channels=[0, 1, 2])\n",
    "pruned_model = surgeon.operate()\n",
    "\n",
    "\n",
    "# Suppression des canaux 0, 1 et 2 de la couche Conv2D\n",
    "\n",
    "\n",
    "\n",
    "# Créer une nouvelle entrée et sortie pour le modèle après suppression des canaux\n",
    "pruned_model_input = pruned_model.input\n",
    "pruned_model_output = pruned_model.output\n",
    "\n",
    "# Créer un nouveau modèle pruné à partir des nouvelles entrées et sorties\n",
    "pruned_model = Model(inputs=pruned_model_input, outputs=pruned_model_output)\n",
    "\n",
    "# Recompiler le modèle pour s'assurer qu'il est prêt\n",
    "pruned_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Affichage du résumé du modèle pour vérifier la suppression des canaux\n",
    "pruned_model.summary()\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "c6d1ec64b9ed2b03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tf_keras.src.engine.keras_tensor.KerasTensor'>\n",
      "Deleting 3/32 channels from layer: conv2d_20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All `inputs` values must be KerasTensors. Received: inputs=[<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_8')>] including invalid value KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\") of type <class 'tf_keras.src.engine.keras_tensor.KerasTensor'>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 30\u001B[0m\n\u001B[0;32m     28\u001B[0m surgeon \u001B[38;5;241m=\u001B[39m Surgeon(testt_model)\n\u001B[0;32m     29\u001B[0m surgeon\u001B[38;5;241m.\u001B[39madd_job(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdelete_channels\u001B[39m\u001B[38;5;124m'\u001B[39m, layer_0, channels\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m])\n\u001B[1;32m---> 30\u001B[0m pruned_model \u001B[38;5;241m=\u001B[39m \u001B[43msurgeon\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moperate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m# Suppression des canaux 0, 1 et 2 de la couche Conv2D\u001B[39;00m\n\u001B[0;32m     34\u001B[0m \n\u001B[0;32m     35\u001B[0m \n\u001B[0;32m     36\u001B[0m \n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# Créer une nouvelle entrée et sortie pour le modèle après suppression des canaux\u001B[39;00m\n\u001B[0;32m     38\u001B[0m pruned_model_input \u001B[38;5;241m=\u001B[39m pruned_model\u001B[38;5;241m.\u001B[39minput\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf2kerassurgeon\\surgeon.py:166\u001B[0m, in \u001B[0;36mSurgeon.operate\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    164\u001B[0m     output_nodes\u001B[38;5;241m.\u001B[39mappend(get_inbound_nodes(layer)[node_index])\n\u001B[0;32m    165\u001B[0m new_outputs, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_rebuild_graph(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39minputs, output_nodes)\n\u001B[1;32m--> 166\u001B[0m new_model \u001B[38;5;241m=\u001B[39m \u001B[43mModel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_copy:\n\u001B[0;32m    169\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m utils\u001B[38;5;241m.\u001B[39mclean_copy(new_model)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\keras\\src\\utils\\tracking.py:26\u001B[0m, in \u001B[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(fn)\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m DotNotTrackScope():\n\u001B[1;32m---> 26\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\keras\\src\\models\\functional.py:119\u001B[0m, in \u001B[0;36mFunctional.__init__\u001B[1;34m(self, inputs, outputs, name, **kwargs)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m flat_inputs:\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, backend\u001B[38;5;241m.\u001B[39mKerasTensor):\n\u001B[1;32m--> 119\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    120\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll `inputs` values must be KerasTensors. Received: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    121\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minputs=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00minputs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m including invalid value \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    122\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(x)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    123\u001B[0m         )\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m flat_outputs:\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, backend\u001B[38;5;241m.\u001B[39mKerasTensor):\n",
      "\u001B[1;31mValueError\u001B[0m: All `inputs` values must be KerasTensors. Received: inputs=[<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_8')>] including invalid value KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\") of type <class 'tf_keras.src.engine.keras_tensor.KerasTensor'>"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c6ced99d95b47b66"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:22:59.096133Z",
     "start_time": "2024-11-26T18:22:59.079400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tf_keras import optimizers\n",
    "import tempfile\n",
    "import tensorflow_model_optimization as tfmot\n",
    "# Finish pruning after 2 epochs\n",
    "epochs = 2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def prune_model(model, initial_sparsity, final_sparsity, train_data=train_batches, val_data=validation_batches, epochs=epochs, feature_extractor=model ):\n",
    "\n",
    "  # Create a tensorboard logfile\n",
    "  logdir = tempfile.mkdtemp()\n",
    "  # The end_step is the total number of iterations required for the training data which is basically the entire epochs over the length of the training data\n",
    "  end_step = int(len(train_data) * epochs * 0.5)\n",
    "  # Import the low-magnitude-pruning function\n",
    "  prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "  # Set the prunung params\n",
    "  pruning_params = {\n",
    "\n",
    "      \"pruning_schedule\" : tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0,\n",
    "                                                                final_sparsity=final_sparsity,\n",
    "                                                                begin_step=0,\n",
    "                                                                end_step=end_step)\n",
    "\n",
    "                  }\n",
    "\n",
    "\n",
    "  learning_rate_fn = optimizers.schedules.PolynomialDecay(\n",
    "    0.001,\n",
    "    1000,\n",
    "    0.0001,\n",
    "    power=0.5)\n",
    "\n",
    "  # Model for pruning\n",
    "  #feature_extractor = prune_low_magnitude(feature_extractor, **pruning_params)\n",
    "  model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "  # Recompile\n",
    "  model_for_pruning.compile(optimizer= optimizers.Adam(),\n",
    "                            loss= losses.SparseCategoricalCrossentropy(),\n",
    "                            metrics=[\"accuracy\"])\n",
    "  #create callbacks\n",
    "  callbacks = [tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "              tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "               #create_model_checkpoint(model_name=model.name),\n",
    "              #tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                                  #patience=3,\n",
    "                                                  #verbose=1),\n",
    "               #tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                        #patience=4,\n",
    "                                                        #restore_best_weights=True)\n",
    "                                                        ]\n",
    "\n",
    "  # Fit the model\n",
    "  model_for_pruning.fit(train_data,\n",
    "                      validation_data=val_data,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=epochs,\n",
    "                      callbacks=callbacks)\n",
    "\n",
    "  # Save the model\n",
    "  #model_for_pruning.save(f\"mnist_model_sparsity_{final_sparsity}\")\n",
    "\n",
    "  # Evaluate the model\n",
    "  score = model_for_pruning.evaluate(val_data, verbose=0)\n",
    "  metric_dict = {\n",
    "      \"sparsity\" : final_sparsity,\n",
    "      \"val_loss\" : np.round(score[0], 4),\n",
    "      \"val_accuracy\" : np.round(score[1] * 100, 4)\n",
    "  }\n",
    "  return logdir, metric_dict, model_for_pruning"
   ],
   "id": "1b6ca5bc33f329d7",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:42:42.156292Z",
     "start_time": "2024-11-26T18:34:00.731545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Choose the best sparsity level\n",
    "final_sparsity = 0.80\n",
    "\n",
    "logdir, metrics, pruned_model = prune_model(model=pruned_model,\n",
    "          initial_sparsity=0,\n",
    "          final_sparsity=final_sparsity,\n",
    "          epochs=3)"
   ],
   "id": "cdc4c59b2c928e7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "23/23 [==============================] - 159s 7s/step - loss: 0.6922 - accuracy: 0.5257 - val_loss: 0.6947 - val_accuracy: 0.4838\n",
      "Epoch 2/3\n",
      "23/23 [==============================] - 174s 8s/step - loss: 0.6920 - accuracy: 0.5257 - val_loss: 0.6949 - val_accuracy: 0.4838\n",
      "Epoch 3/3\n",
      "23/23 [==============================] - 145s 6s/step - loss: 0.6920 - accuracy: 0.5257 - val_loss: 0.6949 - val_accuracy: 0.4838\n"
     ]
    }
   ],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:31:41.121678Z",
     "start_time": "2024-11-26T18:31:40.682077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ],
   "id": "e6302f2afcdb5cfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neyen\\AppData\\Local\\Temp\\ipykernel_71452\\369930696.py:4: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: C:\\Users\\neyen\\AppData\\Local\\Temp\\tmpjh1lij65.h5\n"
     ]
    }
   ],
   "execution_count": 196
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1bb836c8b0e399f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
