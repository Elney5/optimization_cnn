{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import pydot\n",
    "import tempfile\n",
    "import graphviz\n",
    "import pandas as pd\n",
    "from tf_keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import keras"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:01:25.323777Z",
     "start_time": "2024-11-21T05:01:25.226491400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing the dataset Horses or Humans"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "(train_examples, validation_examples), info = tfds.load(\n",
    "    'horses_or_humans',\n",
    "    split = ('train[:70%]', 'train[70%:]'),\n",
    "    with_info = True,\n",
    "    as_supervised = True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:01:25.522749700Z",
     "start_time": "2024-11-21T05:01:25.244390500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(1027, 2, ['horses', 'humans'])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Information about the dataset Horses or Humans\n",
    "num_examples = info.splits['train'].num_examples\n",
    "num_classes = info.features['label'].num_classes\n",
    "class_names = info.features['label'].names\n",
    "num_examples,num_classes, class_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:01:25.547610600Z",
     "start_time": "2024-11-21T05:01:25.341040700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Converting the images to the required size for TensorFlow Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def format_image(image, label):\n",
    "  image = tf.image.resize(image, IMG_SIZE)\n",
    "  return image,label\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "train_batches = train_examples.cache().shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:01:25.548609400Z",
     "start_time": "2024-11-21T05:01:25.357737200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batches"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:01:25.548609400Z",
     "start_time": "2024-11-21T05:01:25.402704500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating the Model using Transfer Learning with VGG16 Model and Personal Classification Layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_horses_or_humans.keras\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 14, 14, 512)       7635264   \n",
      "                                                                 \n",
      " global_max_pooling2d_1 (Gl  (None, 512)               0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7636290 (29.13 MB)\n",
      "Trainable params: 1026 (4.01 KB)\n",
      "Non-trainable params: 7635264 (29.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tf_keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tf_keras.models import Model\n",
    "from tf_keras.applications import VGG16\n",
    "from tf_keras import layers\n",
    "from tf_keras import Sequential\n",
    "from tf_keras.layers import Input\n",
    "from tf_keras import losses\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# Create the base model from the pre-trained model VGG16 for transfer learning\n",
    "vgg16_model = VGG16(input_shape=(224, 224, 3),\n",
    "                    include_top=False,\n",
    "                    weights='imagenet')\n",
    "# Freeze the base model\n",
    "vgg16_model.trainable = False\n",
    "\n",
    "# Create a sequential mode\n",
    "test_model = Sequential()\n",
    "for layer in vgg16_model.layers[:-4]:\n",
    "    test_model.add(layer)\n",
    "\n",
    "del vgg16_model\n",
    "\n",
    "for layer in test_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "# Add personal classification layers on top of the base model\n",
    "max_pool_layer = layers.GlobalMaxPooling2D()\n",
    "prediction_layer = layers.Dense(2, activation='softmax')  # For binary classification (2 classes)\n",
    "\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = test_model(inputs)  # Use default training=True behavior\n",
    "x = max_pool_layer(x)\n",
    "x = layers.Dropout(0.3)(x)  # Apply dropout during training\n",
    "outputs = prediction_layer(x)\n",
    "model = Model(inputs, outputs, name='model_horses_or_humans.keras')\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:01:26.278090700Z",
     "start_time": "2024-11-21T05:01:25.430337800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compile the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from compilation import create_model_checkpoint"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:01:26.297819300Z",
     "start_time": "2024-11-21T05:01:26.251579500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tf_keras\\src\\optimizers\\__init__.py:317: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tf_keras\\src\\optimizers\\__init__.py:317: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:01:26.389443Z",
     "start_time": "2024-11-21T05:01:26.278090700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 112s 5s/step - loss: 507.0986 - accuracy: 0.4951 - val_loss: 292.8456 - val_accuracy: 0.5260\n",
      "Epoch 2/3\n",
      "23/23 [==============================] - 105s 5s/step - loss: 362.3079 - accuracy: 0.5508 - val_loss: 41.9744 - val_accuracy: 0.8214\n",
      "Epoch 3/3\n",
      "23/23 [==============================] - 106s 5s/step - loss: 234.8583 - accuracy: 0.6565 - val_loss: 17.9485 - val_accuracy: 0.9156\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "history = model.fit(train_batches,\n",
    "                    epochs = EPOCHS,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    validation_data = validation_batches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:06:49.440395800Z",
     "start_time": "2024-11-21T05:01:26.391443Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "test_model.trainable = True\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 2\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in test_model.layers[:-fine_tune_at]:\n",
    "  layer.trainable =  False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:06:49.470620900Z",
     "start_time": "2024-11-21T05:06:49.460345200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "model.compile(loss=losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:06:49.518231400Z",
     "start_time": "2024-11-21T05:06:49.484213Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "23/23 [==============================] - 119s 5s/step - loss: 102.6089 - accuracy: 0.8414 - val_loss: 3.1261 - val_accuracy: 0.9838\n",
      "Epoch 2/5\n",
      "23/23 [==============================] - 116s 5s/step - loss: 26.0901 - accuracy: 0.9513 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "23/23 [==============================] - 126s 6s/step - loss: 6.8400 - accuracy: 0.9847 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "23/23 [==============================] - 118s 5s/step - loss: 4.9745 - accuracy: 0.9917 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "23/23 [==============================] - 117s 5s/step - loss: 2.4566 - accuracy: 0.9917 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "history = model.fit(train_batches,\n",
    "                    epochs = EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_data = validation_batches,\n",
    "                    callbacks=[create_model_checkpoint(model_name=model.name)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:16:46.288024900Z",
     "start_time": "2024-11-21T05:06:49.515268Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from tf_keras.utils import plot_model\n",
    "import pydot\n",
    "import graphviz\n",
    "plot_model(model, to_file=\"horses_or_humans_vgg16.jpeg\",show_shapes=True, show_dtype=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:16:46.334935200Z",
     "start_time": "2024-11-21T05:16:46.297329Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the model and history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from tf_keras import models\n",
    "model_1 = models.load_model('model_experiments/model_horses_or_humans.keras')\n",
    "history_1 = history.history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:16:48.448360300Z",
     "start_time": "2024-11-21T05:16:46.336856600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 32s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.0, 1.0]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(validation_batches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:17:20.921524Z",
     "start_time": "2024-11-21T05:16:48.457568400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "model.save_weights(\"save_weights.weights.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:17:21.044626200Z",
     "start_time": "2024-11-21T05:17:20.924525700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_horses_or_humans.keras\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 14, 14, 512)       7635264   \n",
      "                                                                 \n",
      " global_max_pooling2d_1 (Gl  (None, 512)               0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7636290 (29.13 MB)\n",
      "Trainable params: 2360834 (9.01 MB)\n",
      "Non-trainable params: 5275456 (20.12 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:17:21.134070200Z",
     "start_time": "2024-11-21T05:17:21.046626600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "val_data = validation_examples\n",
    "val_data = val_data.map(format_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "print(val_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:17:21.160672900Z",
     "start_time": "2024-11-21T05:17:21.080414300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<_MapDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32), label\n",
    "\n",
    "val_data = val_data.map(normalize_img)\n",
    "val_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:17:21.242967400Z",
     "start_time": "2024-11-21T05:17:21.158672900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate the model on the test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 32s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "The accuracy of the baseline model is 100.00 %\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'sparsity': 0, 'val_loss': 0.0, 'val_accuracy': 100.0}"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_score = model_1.evaluate(validation_batches)\n",
    "print(f\"The accuracy of the baseline model is {baseline_score[1] * 100:.2f} %\")\n",
    "base_metrics = {\n",
    "      \"sparsity\" : 0,\n",
    "      \"val_loss\" : np.round(baseline_score[0], 4),\n",
    "      \"val_accuracy\" : np.round(baseline_score[1] * 100, 4)\n",
    "}\n",
    "base_metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:17:52.811336400Z",
     "start_time": "2024-11-21T05:17:21.226597500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the model and history\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_MapDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as Image\n",
    "\n",
    "print(val_data)\n",
    "\n",
    "def benchmark(model, class_names=class_names, image_size=IMG_SIZE):\n",
    "  file_count = 0\n",
    "  infer_times = []\n",
    "  init_timer = 0\n",
    "\n",
    "  for image in val_data:\n",
    "    if file_count < 1 :\n",
    "        init_timer_start = time.time()\n",
    "        pred = model.predict(image[0])\n",
    "        pred_class = class_names[int(np.argmax(pred[0]))]\n",
    "        init_timer_end = time.time()\n",
    "        init_timer = init_timer_end - init_timer_start\n",
    "        file_count+=1\n",
    "    else:\n",
    "        timer_start = time.time()\n",
    "        pred = model.predict(image[0])\n",
    "        pred_class = class_names[int(np.argmax(pred[0]))]\n",
    "        timer_end = time.time()\n",
    "        infer_times.append((timer_end - timer_start))\n",
    "        file_count+=1\n",
    "\n",
    "  return init_timer, np.mean(infer_times), np.std(infer_times)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:17:52.882865Z",
     "start_time": "2024-11-21T05:17:52.820468900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m init_time, avg_time, std \u001B[38;5;241m=\u001B[39m \u001B[43mbenchmark\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe first image takes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minit_time\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1000\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ms\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe average time taken per 99 images \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mavg_time\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1000\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ms\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[30], line 20\u001B[0m, in \u001B[0;36mbenchmark\u001B[1;34m(model, class_names, image_size)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     19\u001B[0m     timer_start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m---> 20\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m     pred_class \u001B[38;5;241m=\u001B[39m class_names[\u001B[38;5;28mint\u001B[39m(np\u001B[38;5;241m.\u001B[39margmax(pred[\u001B[38;5;241m0\u001B[39m]))]\n\u001B[0;32m     22\u001B[0m     timer_end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tf_keras\\src\\engine\\training.py:2650\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   2648\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39msteps():\n\u001B[0;32m   2649\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_predict_batch_begin(step)\n\u001B[1;32m-> 2650\u001B[0m     tmp_batch_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2651\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   2652\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    875\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[0;32m    880\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[0;32m    882\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    883\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1324\u001B[0m     args,\n\u001B[0;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1326\u001B[0m     executing_eagerly)\n\u001B[0;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    261\u001B[0m     )\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1681\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1682\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1683\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1684\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1685\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1686\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1687\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1688\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1689\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1690\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1691\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1692\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1693\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1697\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1698\u001B[0m   )\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "init_time, avg_time, std = benchmark(model=model_1)\n",
    "print(f\"The first image takes {init_time * 1000:.2f} ms\")\n",
    "print(f\"The average time taken per 99 images {avg_time * 1000:.2f} ms\")\n",
    "print(f\"The standard deviation of samples is {std * 1000:.2f} ms\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:18:19.828155Z",
     "start_time": "2024-11-21T05:17:52.829654100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization.python.core.sparsity as sparsity\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "\n",
    "# Finish pruning after 2 epochs\n",
    "epochs = 2\n",
    "BATCH_SIZE = 32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:18:24.293232400Z",
     "start_time": "2024-11-21T05:18:24.265844300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "\n",
    "def prune_model(model, initial_sparsity, final_sparsity, train_data=train_batches, val_data=validation_batches, epochs=epochs, feature_extractor=model ):\n",
    "\n",
    "  # Create a tensorboard logfile\n",
    "  logdir = tempfile.mkdtemp()\n",
    "  # The end_step is the total number of iterations required for the training data which is basically the entire epochs over the length of the training data\n",
    "  end_step = int(len(train_data) * epochs * 0.5)\n",
    "  # Import the low-magnitude-pruning function\n",
    "  prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "  # Set the prunung params\n",
    "  pruning_params = {\n",
    "\n",
    "      \"pruning_schedule\" : tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0,\n",
    "                                                                final_sparsity=final_sparsity,\n",
    "                                                                begin_step=0,\n",
    "                                                                end_step=end_step)\n",
    "\n",
    "                  }\n",
    "\n",
    "\n",
    "  learning_rate_fn = keras.optimizers.schedules.PolynomialDecay(\n",
    "    0.001,\n",
    "    1000,\n",
    "    0.0001,\n",
    "    power=0.5)\n",
    "\n",
    "  # Model for pruning\n",
    "  #feature_extractor = prune_low_magnitude(feature_extractor, **pruning_params)\n",
    "  model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "  # Recompile\n",
    "  model_for_pruning.compile(optimizer= optimizers.Adam(),\n",
    "                            loss= losses.SparseCategoricalCrossentropy(),\n",
    "                            metrics=[\"accuracy\"])\n",
    "  #create callbacks\n",
    "  callbacks = [tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "              tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "               #create_model_checkpoint(model_name=model.name),\n",
    "              #tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                                  #patience=3,\n",
    "                                                  #verbose=1),\n",
    "               #tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                        #patience=4,\n",
    "                                                        #restore_best_weights=True)\n",
    "                                                        ]\n",
    "\n",
    "  # Fit the model\n",
    "  model_for_pruning.fit(train_data,\n",
    "                      validation_data=val_data,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=epochs,\n",
    "                      callbacks=callbacks)\n",
    "\n",
    "  # Save the model\n",
    "  #model_for_pruning.save(f\"mnist_model_sparsity_{final_sparsity}\")\n",
    "\n",
    "  # Evaluate the model\n",
    "  score = model_for_pruning.evaluate(val_data, verbose=0)\n",
    "  metric_dict = {\n",
    "      \"sparsity\" : final_sparsity,\n",
    "      \"val_loss\" : np.round(score[0], 4),\n",
    "      \"val_accuracy\" : np.round(score[1] * 100, 4)\n",
    "  }\n",
    "  return logdir, metric_dict, model_for_pruning"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T05:18:27.446584Z",
     "start_time": "2024-11-21T05:18:27.427538600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "23/23 [==============================] - 122s 5s/step - loss: 98.8900 - accuracy: 0.9221 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 118s 5s/step - loss: 1.1279 - accuracy: 0.9958 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 115s 5s/step - loss: 0.1049 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 116s 5s/step - loss: 7.9411 - accuracy: 0.9944 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 115s 5s/step - loss: 2.5023 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 116s 5s/step - loss: 1.2839 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 117s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.7402 - val_accuracy: 0.9968\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 115s 5s/step - loss: 0.1475 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 1.4875 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 1.8271 - accuracy: 0.9958 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 115s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 115s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 117s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 115s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Sparsity : 0.25 \tValidation Loss: 0.0, \tValidation Accuracy: 100.0\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 118s 5s/step - loss: 183.0875 - accuracy: 0.8985 - val_loss: 8.9040 - val_accuracy: 0.9870\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 115s 5s/step - loss: 6.6566 - accuracy: 0.9875 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.2130 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 115s 5s/step - loss: 1.8270e-07 - accuracy: 1.0000 - val_loss: 2.9668 - val_accuracy: 0.9968\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 2.5739 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.2771 - accuracy: 0.9972 - val_loss: 3.4749 - val_accuracy: 0.9968\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 1.6782 - accuracy: 0.9958 - val_loss: 18.7554 - val_accuracy: 0.9740\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 9.7864 - accuracy: 0.9875 - val_loss: 0.8153 - val_accuracy: 0.9903\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 8.0123 - accuracy: 0.9847 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.8292 - accuracy: 0.9944 - val_loss: 2.6401 - val_accuracy: 0.9968\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.6613 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 115s 5s/step - loss: 0.0115 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 120s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Sparsity : 0.5 \tValidation Loss: 0.0, \tValidation Accuracy: 100.0\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 117s 5s/step - loss: 216.5893 - accuracy: 0.8818 - val_loss: 0.7485 - val_accuracy: 0.9968\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 4.9821 - accuracy: 0.9930 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.2747 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.1233 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.7820 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 117s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 3.9329 - accuracy: 0.9917 - val_loss: 2.8291 - val_accuracy: 0.9838\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 5.6029 - accuracy: 0.9819 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.0645 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.4565 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.0097 - accuracy: 0.9986 - val_loss: 1.0206 - val_accuracy: 0.9968\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 6.1212 - accuracy: 0.9875 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.6053 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 1.3073 - accuracy: 0.9944 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Sparsity : 0.6 \tValidation Loss: 0.0, \tValidation Accuracy: 100.0\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 119s 5s/step - loss: 256.2952 - accuracy: 0.8512 - val_loss: 16.2002 - val_accuracy: 0.9773\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 115s 5s/step - loss: 5.5313 - accuracy: 0.9958 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 2.7159 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 116s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 2.0151 - accuracy: 0.9930 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.7296 - accuracy: 0.9958 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 2.4048 - accuracy: 0.9889 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.7298 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 5.4380 - accuracy: 0.9791 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 2.0838 - accuracy: 0.9917 - val_loss: 0.1279 - val_accuracy: 0.9968\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 2.0545 - accuracy: 0.9930 - val_loss: 0.8158 - val_accuracy: 0.9968\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.5426 - accuracy: 0.9972 - val_loss: 0.8359 - val_accuracy: 0.9968\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.7718 - accuracy: 0.9930 - val_loss: 0.5494 - val_accuracy: 0.9968\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 0.0813 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.4687 - accuracy: 0.9958 - val_loss: 0.1820 - val_accuracy: 0.9968\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 0.1217 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.3566 - accuracy: 0.9972 - val_loss: 0.9639 - val_accuracy: 0.9968\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.1891 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0383 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 119s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Sparsity : 0.7 \tValidation Loss: 0.0, \tValidation Accuracy: 100.0\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 117s 5s/step - loss: 238.5384 - accuracy: 0.8846 - val_loss: 1.7716 - val_accuracy: 0.9968\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 115s 5s/step - loss: 0.1777 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 2.5614 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 116s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 116s 5s/step - loss: 7.3931 - accuracy: 0.9750 - val_loss: 1.3362 - val_accuracy: 0.9903\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 4.6673 - accuracy: 0.9791 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 0.9629 - accuracy: 0.9930 - val_loss: 1.4057 - val_accuracy: 0.9935\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 13.4419 - accuracy: 0.9402 - val_loss: 11.3400 - val_accuracy: 0.8929\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 12.7023 - accuracy: 0.9138 - val_loss: 0.3875 - val_accuracy: 0.9903\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 115s 5s/step - loss: 2.0979 - accuracy: 0.9764 - val_loss: 1.0972 - val_accuracy: 0.9740\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 2.8980 - accuracy: 0.9694 - val_loss: 1.3376 - val_accuracy: 0.9773\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 1.3308 - accuracy: 0.9777 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 1.2881 - accuracy: 0.9833 - val_loss: 0.6569 - val_accuracy: 0.9870\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 0.2929 - accuracy: 0.9930 - val_loss: 0.0677 - val_accuracy: 0.9935\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 1.3300 - accuracy: 0.9777 - val_loss: 0.9246 - val_accuracy: 0.9870\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.3337 - accuracy: 0.9917 - val_loss: 0.7336 - val_accuracy: 0.9870\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.0668 - accuracy: 0.9972 - val_loss: 8.9035e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 1.6237 - accuracy: 0.9805 - val_loss: 0.0440 - val_accuracy: 0.9968\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.1605 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Sparsity : 0.8 \tValidation Loss: 0.0, \tValidation Accuracy: 100.0\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 118s 5s/step - loss: 224.1858 - accuracy: 0.8957 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 116s 5s/step - loss: 0.1829 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 1.4945e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 36.1731 - accuracy: 0.8985 - val_loss: 1.2968 - val_accuracy: 0.9870\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 5.0662 - accuracy: 0.9736 - val_loss: 3.6877 - val_accuracy: 0.9708\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 6.4717 - accuracy: 0.9750 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 1.5782 - accuracy: 0.9833 - val_loss: 1.1925 - val_accuracy: 0.9838\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 9.0798 - accuracy: 0.8567 - val_loss: 11.3991 - val_accuracy: 0.5714\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 3.1883 - accuracy: 0.5688 - val_loss: 0.7324 - val_accuracy: 0.5584\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.6787 - accuracy: 0.5744 - val_loss: 0.6743 - val_accuracy: 0.6331\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 110s 5s/step - loss: 0.6641 - accuracy: 0.5744 - val_loss: 0.6801 - val_accuracy: 0.5584\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6798 - accuracy: 0.5549 - val_loss: 0.7004 - val_accuracy: 0.4968\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6790 - accuracy: 0.5675 - val_loss: 0.6294 - val_accuracy: 0.6299\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6788 - accuracy: 0.5508 - val_loss: 0.6927 - val_accuracy: 0.5162\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 0.6721 - accuracy: 0.5661 - val_loss: 0.7024 - val_accuracy: 0.4968\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6827 - accuracy: 0.5341 - val_loss: 0.7092 - val_accuracy: 0.4903\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6828 - accuracy: 0.5396 - val_loss: 0.6887 - val_accuracy: 0.5325\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6792 - accuracy: 0.5424 - val_loss: 0.7052 - val_accuracy: 0.4870\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6845 - accuracy: 0.5285 - val_loss: 0.7021 - val_accuracy: 0.4870\n",
      "Sparsity : 0.9 \tValidation Loss: 0.7021, \tValidation Accuracy: 48.7013\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 119s 5s/step - loss: 81.4377 - accuracy: 0.9277 - val_loss: 6.8391 - val_accuracy: 0.9805\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 115s 5s/step - loss: 10.5783 - accuracy: 0.9958 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 2.3923 - accuracy: 0.9958 - val_loss: 14.8035 - val_accuracy: 0.9870\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 3.0439 - accuracy: 0.9930 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 19.0677 - accuracy: 0.8971 - val_loss: 5.0167 - val_accuracy: 0.9740\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 117s 5s/step - loss: 21.0766 - accuracy: 0.9026 - val_loss: 5.3827 - val_accuracy: 0.9708\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 115s 5s/step - loss: 7.2254 - accuracy: 0.9471 - val_loss: 2.0899 - val_accuracy: 0.9903\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 4.5896 - accuracy: 0.9652 - val_loss: 2.7803 - val_accuracy: 0.9740\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 6.9792 - accuracy: 0.8234 - val_loss: 7.5134 - val_accuracy: 0.5162\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 110s 5s/step - loss: 4.3429 - accuracy: 0.5063 - val_loss: 0.6922 - val_accuracy: 0.5130\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 110s 5s/step - loss: 0.6935 - accuracy: 0.4896 - val_loss: 0.6935 - val_accuracy: 0.4870\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6902 - accuracy: 0.5285 - val_loss: 0.6965 - val_accuracy: 0.4838\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6900 - accuracy: 0.5271 - val_loss: 0.6988 - val_accuracy: 0.4838\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 0.6864 - accuracy: 0.5271 - val_loss: 0.7019 - val_accuracy: 0.4838\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6925 - accuracy: 0.5229 - val_loss: 0.6997 - val_accuracy: 0.4838\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6911 - accuracy: 0.5257 - val_loss: 0.6997 - val_accuracy: 0.4838\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 0.6896 - accuracy: 0.5257 - val_loss: 0.6995 - val_accuracy: 0.4838\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6913 - accuracy: 0.5257 - val_loss: 0.6987 - val_accuracy: 0.4838\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6887 - accuracy: 0.5313 - val_loss: 0.6978 - val_accuracy: 0.4903\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6872 - accuracy: 0.5424 - val_loss: 0.6898 - val_accuracy: 0.4968\n",
      "Sparsity : 0.95 \tValidation Loss: 0.6898, \tValidation Accuracy: 49.6753\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 118s 5s/step - loss: 255.0805 - accuracy: 0.8540 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 118s 5s/step - loss: 14.6654 - accuracy: 0.9903 - val_loss: 2.3578 - val_accuracy: 0.9968\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 8.2023 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 54.7969 - accuracy: 0.8275 - val_loss: 7.3766 - val_accuracy: 0.9513\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 20.0756 - accuracy: 0.8915 - val_loss: 1.5377 - val_accuracy: 0.9578\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 3.6028 - accuracy: 0.9569 - val_loss: 0.2485 - val_accuracy: 0.9968\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 2.5910 - accuracy: 0.9666 - val_loss: 0.4893 - val_accuracy: 0.9838\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 4.0093 - accuracy: 0.8261 - val_loss: 0.8396 - val_accuracy: 0.5714\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 1.2192 - accuracy: 0.5494 - val_loss: 0.6900 - val_accuracy: 0.5195\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6934 - accuracy: 0.5382 - val_loss: 0.6848 - val_accuracy: 0.5487\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 110s 5s/step - loss: 0.6909 - accuracy: 0.5730 - val_loss: 0.6893 - val_accuracy: 0.5390\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6929 - accuracy: 0.5257 - val_loss: 0.6966 - val_accuracy: 0.4903\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6932 - accuracy: 0.5285 - val_loss: 0.6972 - val_accuracy: 0.4870\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6915 - accuracy: 0.5243 - val_loss: 0.6988 - val_accuracy: 0.4903\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6914 - accuracy: 0.5299 - val_loss: 0.6986 - val_accuracy: 0.4903\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 110s 5s/step - loss: 0.6916 - accuracy: 0.5285 - val_loss: 0.6987 - val_accuracy: 0.4903\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 0.6909 - accuracy: 0.5299 - val_loss: 0.6989 - val_accuracy: 0.4935\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6931 - accuracy: 0.5243 - val_loss: 0.6978 - val_accuracy: 0.4968\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6919 - accuracy: 0.5271 - val_loss: 0.6988 - val_accuracy: 0.4968\n",
      "Sparsity : 0.97 \tValidation Loss: 0.6988, \tValidation Accuracy: 49.6753\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 118s 5s/step - loss: 491.4601 - accuracy: 0.8540 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 2.2125 - accuracy: 0.9972 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 118s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 113s 5s/step - loss: 35.4786 - accuracy: 0.8359 - val_loss: 13.8184 - val_accuracy: 0.8766\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 26.9808 - accuracy: 0.8401 - val_loss: 30.6221 - val_accuracy: 0.7468\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 112s 5s/step - loss: 10.0088 - accuracy: 0.9124 - val_loss: 8.4118 - val_accuracy: 0.9123\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 7.2839 - accuracy: 0.9277 - val_loss: 0.4797 - val_accuracy: 0.9740\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 2.3957 - accuracy: 0.8067 - val_loss: 0.8770 - val_accuracy: 0.4903\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 110s 5s/step - loss: 1.4068 - accuracy: 0.5104 - val_loss: 0.9199 - val_accuracy: 0.4838\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 110s 5s/step - loss: 0.7980 - accuracy: 0.5174 - val_loss: 0.7056 - val_accuracy: 0.4675\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 110s 5s/step - loss: 0.7341 - accuracy: 0.5118 - val_loss: 0.7024 - val_accuracy: 0.4286\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.7136 - accuracy: 0.5090 - val_loss: 0.6959 - val_accuracy: 0.4740\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 114s 5s/step - loss: 0.7203 - accuracy: 0.4993 - val_loss: 0.6919 - val_accuracy: 0.4935\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 110s 5s/step - loss: 0.7004 - accuracy: 0.5118 - val_loss: 0.6887 - val_accuracy: 0.4870\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6953 - accuracy: 0.5243 - val_loss: 0.6891 - val_accuracy: 0.5195\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6975 - accuracy: 0.5146 - val_loss: 0.6875 - val_accuracy: 0.5227\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 110s 5s/step - loss: 0.6967 - accuracy: 0.4937 - val_loss: 0.6921 - val_accuracy: 0.5130\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6888 - accuracy: 0.5369 - val_loss: 0.6961 - val_accuracy: 0.5097\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 111s 5s/step - loss: 0.6896 - accuracy: 0.5522 - val_loss: 0.6889 - val_accuracy: 0.5032\n",
      "Sparsity : 0.99 \tValidation Loss: 0.6889, \tValidation Accuracy: 50.3247\n"
     ]
    }
   ],
   "source": [
    "from tf_keras import models\n",
    "k_sparsities = [0.25, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.97, 0.99]\n",
    "\n",
    "#k_sparsities = [0.50]\n",
    "metric_list = []\n",
    "\n",
    "for k in k_sparsities:\n",
    "  # Load in the best saved model\n",
    "  model_1 = models.load_model(\"model_experiments/model_horses_or_humans.keras\")\n",
    "  logdir, metrics, pruned_model = prune_model(model=model_1,\n",
    "            initial_sparsity=0,\n",
    "            final_sparsity=k,\n",
    "            epochs=20)\n",
    "  val_loss, val_accuracy  = metrics[\"val_loss\"], metrics[\"val_accuracy\"]\n",
    "  metric_list.append(metrics)\n",
    "  print(f\"Sparsity : {k} \\tValidation Loss: {val_loss}, \\tValidation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Create a dataframe of the values obtained\n",
    "df = pd.DataFrame(metric_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T11:03:29.378194400Z",
     "start_time": "2024-11-21T05:18:30.012329500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "   sparsity  val_loss  val_accuracy\n0      0.25    0.0000      100.0000\n1      0.50    0.0000      100.0000\n2      0.60    0.0000      100.0000\n3      0.70    0.0000      100.0000\n4      0.80    0.0000      100.0000\n5      0.90    0.7021       48.7013\n6      0.95    0.6898       49.6753\n7      0.97    0.6988       49.6753\n8      0.99    0.6889       50.3247",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sparsity</th>\n      <th>val_loss</th>\n      <th>val_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.25</td>\n      <td>0.0000</td>\n      <td>100.0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.50</td>\n      <td>0.0000</td>\n      <td>100.0000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.60</td>\n      <td>0.0000</td>\n      <td>100.0000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.70</td>\n      <td>0.0000</td>\n      <td>100.0000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.80</td>\n      <td>0.0000</td>\n      <td>100.0000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.90</td>\n      <td>0.7021</td>\n      <td>48.7013</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.95</td>\n      <td>0.6898</td>\n      <td>49.6753</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.97</td>\n      <td>0.6988</td>\n      <td>49.6753</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.99</td>\n      <td>0.6889</td>\n      <td>50.3247</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T15:16:30.762706600Z",
     "start_time": "2024-11-21T15:16:30.724340Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "df.to_csv(\"pruning_metrics.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T17:22:17.266063700Z",
     "start_time": "2024-11-21T17:22:17.188408700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
