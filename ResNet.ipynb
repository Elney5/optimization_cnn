{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-18T04:52:23.490626400Z",
     "start_time": "2024-12-18T04:52:09.796187Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# IMPORTS",
   "id": "6848ebee221471bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:35:51.747653Z",
     "start_time": "2024-12-18T19:35:51.727155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from configparser import ConfigParser\n",
    "\n",
    "from tf_keras.src.layers import GlobalMaxPooling2D, Dense, Dropout\n",
    "\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\"\n",
    "\n",
    "from tf_keras import losses,optimizers, models, layers, Input\n",
    "from tf_keras.applications import ResNet50\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "from functools import partial\n",
    "from utils import load_dataset, reformat_image, entropy_prune_model,time_benchmark, normalize_img, data_augmentation, unstructured_prune_model, create_model_checkpoint\n",
    "from utils.Objects import PrunedModel, EntropyPruningSurgeon, L1NormPruning\n",
    "from utils.Plots import plot_unstructured_accuracy_sparcity"
   ],
   "id": "9cf2df1f2b1b9e2f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CONSTANTS\n",
    "\n"
   ],
   "id": "276e8f1eefd3bee0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:32:30.110817Z",
     "start_time": "2024-12-18T19:32:30.099011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "BATCH_SIZE = int(config[\"BATCHES\"][\"BATCH_SIZE\"])\n",
    "IMG_SIZE = (int(config[\"IMAGES\"][\"IMG_SIZE_RESNET\"]), int(config[\"IMAGES\"][\"IMG_SIZE_RESNET\"]))\n",
    "\n",
    "MODEL_DIRECTORY = config[\"MODEL\"][\"MODEL_DIRECTORY\"]\n",
    "WEIGHTS_DIRECTORY = config[\"MODEL\"][\"WEIGHTS_DIRECTORY\"]\n",
    "METRICS_DIRECTORY = config[\"MODEL\"][\"METRICS_DIRECTORY\"]\n",
    "\n",
    "UNSTRUCTURED_FLOWERS_WEIGHTS = os.path.join(WEIGHTS_DIRECTORY, config[\"MODEL\"][\"UNSTRUCTURED_FLOWERS_WEIGHTS\"])\n",
    "FLOWERS_MODEL = os.path.join(MODEL_DIRECTORY, config[\"MODEL\"][\"FLOWERS_MODEL\"])\n",
    "UNSTRUCTURED_METRICS = os.path.join(METRICS_DIRECTORY, config[\"MODEL\"][\"UNSTRUCTURED_METRICS\"])\n",
    "IMG_SIZE, BATCH_SIZE"
   ],
   "id": "bc2506c393394515",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 300), 32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:16:37.060978Z",
     "start_time": "2024-12-18T19:16:35.411829Z"
    }
   },
   "cell_type": "code",
   "source": "train_examples, validation_examples, num_examples, num_classes, class_names = load_dataset(\"tf_flowers\", 70)\n",
   "id": "e09d710d1db22ab3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from C:\\Users\\neyen\\tensorflow_datasets\\tf_flowers\\3.0.1\n",
      "INFO:absl:Creating a tf.data.Dataset reading 2 files located in folders: C:\\Users\\neyen\\tensorflow_datasets\\tf_flowers\\3.0.1.\n",
      "INFO:absl:Creating a tf.data.Dataset reading 1 files located in folders: C:\\Users\\neyen\\tensorflow_datasets\\tf_flowers\\3.0.1.\n",
      "INFO:absl:Constructing tf.data.Dataset tf_flowers for split ('train[:70%]', 'train[70%:]'), from C:\\Users\\neyen\\tensorflow_datasets\\tf_flowers\\3.0.1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:16:38.599270Z",
     "start_time": "2024-12-18T19:16:38.590575Z"
    }
   },
   "cell_type": "code",
   "source": "train_examples",
   "id": "e2cd3c4c8e83a6a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:16:40.510063Z",
     "start_time": "2024-12-18T19:16:40.499035Z"
    }
   },
   "cell_type": "code",
   "source": "len(train_examples), len(validation_examples)",
   "id": "8cdcc34e223ec436",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2569, 1101)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:25:56.573820Z",
     "start_time": "2024-12-18T19:25:56.566899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reformat_image(image, label, image_size=IMG_SIZE):\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    return image, label"
   ],
   "id": "f827088ca5d11cd0",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:16:45.642020Z",
     "start_time": "2024-12-18T19:16:44.897766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data augmentation\n",
    "train_examples = train_examples.map(data_augmentation)\n",
    "data_training = train_examples.map(reformat_image).batch(BATCH_SIZE).prefetch(1)\n",
    "data_validation = validation_examples.map(reformat_image).batch(BATCH_SIZE).prefetch(1)\n",
    "data_training, data_validation"
   ],
   "id": "d0369d842b3a1d71",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 300, 300, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n",
       " <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 300, 300, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# AUTOTUNE",
   "id": "a5c64fa7b04536a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:16:59.028651Z",
     "start_time": "2024-12-18T19:16:59.012039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "dataset_training = data_training.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "dataset_validation = data_validation.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "dataset_training, dataset_validation"
   ],
   "id": "645d87d33f21736b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 300, 300, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>,\n",
       " <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 300, 300, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Base Model",
   "id": "f32d7c975339086b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:17:07.973741Z",
     "start_time": "2024-12-18T19:17:05.331089Z"
    }
   },
   "cell_type": "code",
   "source": "base_model = ResNet50(input_shape=IMG_SIZE + (3,), include_top=False, weights=\"imagenet\")",
   "id": "a02cbb5efa39e6dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Freeze the base model",
   "id": "3f12296d61eaed51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:17:10.096492Z",
     "start_time": "2024-12-18T19:17:10.084817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_model.trainable = False\n",
    "max_pool_layer = GlobalMaxPooling2D()\n",
    "prediction_layer = Dense(num_classes, activation=\"softmax\")"
   ],
   "id": "a494624b7906d8ce",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Build the Model",
   "id": "222d533e88cbb263"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:17:13.480841Z",
     "start_time": "2024-12-18T19:17:12.884390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = Input(shape=IMG_SIZE + (3,))\n",
    "x = base_model(inputs, training=False)\n",
    "x = max_pool_layer(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = models.Model(inputs, outputs, name=\"flowers_resnet50.keras\")\n",
    "model.summary()"
   ],
   "id": "5408df14cec194c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"flowers_resnet50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 300, 300, 3)]     0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 10, 10, 2048)      23587712  \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 2048)              0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 10245     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23597957 (90.02 MB)\n",
      "Trainable params: 10245 (40.02 KB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T18:59:20.571002Z",
     "start_time": "2024-12-18T18:59:20.546316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_learning_rate = 0.001\n",
    "model.compile(loss=losses.SparseCategoricalCrossentropy(),\n",
    "                optimizer=optimizers.Adam(learning_rate=base_learning_rate),\n",
    "                metrics=[\"accuracy\"])\n"
   ],
   "id": "c65fe1d7549f2f96",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:01:37.887751Z",
     "start_time": "2024-12-18T19:01:31.526544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "initial_epochs = 10\n",
    "model_history = model.fit(dataset_training,\n",
    "                              validation_data=dataset_training,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              epochs=initial_epochs,\n",
    "                              callbacks=[create_model_checkpoint(model_name=model.name)])"
   ],
   "id": "a113040b933fc1aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'zmq.backend.cython._zmq.Frame.__del__'\n",
      "Traceback (most recent call last):\n",
      "  File \"_zmq.py\", line 160, in zmq.backend.cython._zmq._check_rc\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m initial_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[1;32m----> 2\u001B[0m model_history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcreate_model_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py:1804\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1796\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1797\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1798\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1801\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1802\u001B[0m ):\n\u001B[0;32m   1803\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1804\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1805\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1806\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:869\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    866\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    867\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    868\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 869\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    870\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[0;32m    871\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    872\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    873\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    874\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    875\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1324\u001B[0m     args,\n\u001B[0;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1326\u001B[0m     executing_eagerly)\n\u001B[0;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    261\u001B[0m     )\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1681\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1682\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1683\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1684\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1685\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1686\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1687\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1688\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1689\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1690\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1691\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1692\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1693\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1697\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1698\u001B[0m   )\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:07:44.211456Z",
     "start_time": "2024-12-18T19:07:44.190785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "base_model.trainable = True\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 15\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:-fine_tune_at]:\n",
    "  layer.trainable =  False"
   ],
   "id": "b93676442925e7fd",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:08:02.843068Z",
     "start_time": "2024-12-18T19:08:02.827579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(loss=losses.SparseCategoricalCrossentropy(),\n",
    "                optimizer=optimizers.Adam(learning_rate=base_learning_rate/10),\n",
    "                metrics=[\"accuracy\"])"
   ],
   "id": "cc55804e8cc65f48",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:08:52.285866Z",
     "start_time": "2024-12-18T19:08:52.262298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fine_tune_epochs = 15\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(dataset_training,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=model_history.epoch[-1] + 1,\n",
    "                         validation_data=dataset_training,\n",
    "                         callbacks=[create_model_checkpoint(model_name=model.name)])"
   ],
   "id": "2726f607feee2b61",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 6\u001B[0m\n\u001B[0;32m      1\u001B[0m fine_tune_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m15\u001B[39m\n\u001B[0;32m      2\u001B[0m total_epochs \u001B[38;5;241m=\u001B[39m  initial_epochs \u001B[38;5;241m+\u001B[39m fine_tune_epochs\n\u001B[0;32m      4\u001B[0m history_fine \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfit(dataset_training,\n\u001B[0;32m      5\u001B[0m                          epochs\u001B[38;5;241m=\u001B[39mtotal_epochs,\n\u001B[1;32m----> 6\u001B[0m                          initial_epoch\u001B[38;5;241m=\u001B[39m\u001B[43mmodel_history\u001B[49m\u001B[38;5;241m.\u001B[39mepoch[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m      7\u001B[0m                          validation_data\u001B[38;5;241m=\u001B[39mdataset_training,\n\u001B[0;32m      8\u001B[0m                          callbacks\u001B[38;5;241m=\u001B[39m[create_model_checkpoint(model_name\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mname)])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model_history' is not defined"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:11:39.694257Z",
     "start_time": "2024-12-18T19:11:39.583877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1 = models.load_model(\"model_experiments/flowers_resnet50.keras\")\n",
    "model_1.evaluate(dataset_training)"
   ],
   "id": "d018ca01e641abbb",
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at model_experiments/flowers_resnet50",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model_1 \u001B[38;5;241m=\u001B[39m \u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel_experiments/flowers_resnet50\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\saving\\saving_api.py:262\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001B[0m\n\u001B[0;32m    254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[0;32m    255\u001B[0m         filepath,\n\u001B[0;32m    256\u001B[0m         custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects,\n\u001B[0;32m    257\u001B[0m         \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m,\n\u001B[0;32m    258\u001B[0m         safe_mode\u001B[38;5;241m=\u001B[39msafe_mode,\n\u001B[0;32m    259\u001B[0m     )\n\u001B[0;32m    261\u001B[0m \u001B[38;5;66;03m# Legacy case.\u001B[39;00m\n\u001B[1;32m--> 262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlegacy_sm_saving_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    264\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\saving\\legacy\\save.py:233\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, options)\u001B[0m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(filepath_str, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    232\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mexists(filepath_str):\n\u001B[1;32m--> 233\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\n\u001B[0;32m    234\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo file or directory found at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    235\u001B[0m         )\n\u001B[0;32m    237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39misdir(filepath_str):\n\u001B[0;32m    238\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m saved_model_load\u001B[38;5;241m.\u001B[39mload(\n\u001B[0;32m    239\u001B[0m             filepath_str, \u001B[38;5;28mcompile\u001B[39m, options\n\u001B[0;32m    240\u001B[0m         )\n",
      "\u001B[1;31mOSError\u001B[0m: No file or directory found at model_experiments/flowers_resnet50"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:26:06.640034Z",
     "start_time": "2024-12-18T19:26:06.552707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_data = validation_examples\n",
    "val_data = val_data.map(reformat_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_data = val_data.map(normalize_img)"
   ],
   "id": "11ab836a34f2b9b1",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate the model time",
   "id": "183d31e02cd9c84f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:26:09.901939Z",
     "start_time": "2024-12-18T19:26:09.736774Z"
    }
   },
   "cell_type": "code",
   "source": "init_time, avg_time, std = time_benchmark(model_1, class_names, val_data)",
   "id": "2c38446db8965266",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m init_time, avg_time, std \u001B[38;5;241m=\u001B[39m time_benchmark(\u001B[43mmodel_1\u001B[49m, class_names, val_data)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model_1' is not defined"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pruning the model unstructured",
   "id": "90604bb5c2262719"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:32:44.964307Z",
     "start_time": "2024-12-18T19:32:44.814393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "k_sparsities = [0.25, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.97, 0.99]\n",
    "\n",
    "metric_list = []\n",
    "\n",
    "for k in k_sparsities:\n",
    "    model_1 = models.load_model(\"model_experiments/flowers_resnet50.keras\")\n",
    "    pruned_model: PrunedModel = unstructured_prune_model(model_1, k, 20,data_training, data_validation, BATCH_SIZE)\n",
    "    metrics = pruned_model.metrics\n",
    "    print(f\"{metrics.sparsity=}, \\t {metrics.val_loss=}, \\t {metrics.val_accuracy=}\")\n",
    "    metric_list.append(metrics.to_df())\n",
    "\n",
    "df = pd.concat(metric_list)\n",
    "df.to_csv(UNSTRUCTURED_METRICS)\n",
    "df"
   ],
   "id": "5f1a49fa3c475267",
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at model_experiments/flowers_resnet50",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m metric_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m k_sparsities:\n\u001B[1;32m----> 6\u001B[0m     model_1 \u001B[38;5;241m=\u001B[39m \u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel_experiments/flowers_resnet50\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m     pruned_model: PrunedModel \u001B[38;5;241m=\u001B[39m unstructured_prune_model(model_1, k, data_training, data_validation, BATCH_SIZE)\n\u001B[0;32m      8\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m pruned_model\u001B[38;5;241m.\u001B[39mmetrics\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\saving\\saving_api.py:262\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001B[0m\n\u001B[0;32m    254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[0;32m    255\u001B[0m         filepath,\n\u001B[0;32m    256\u001B[0m         custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects,\n\u001B[0;32m    257\u001B[0m         \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m,\n\u001B[0;32m    258\u001B[0m         safe_mode\u001B[38;5;241m=\u001B[39msafe_mode,\n\u001B[0;32m    259\u001B[0m     )\n\u001B[0;32m    261\u001B[0m \u001B[38;5;66;03m# Legacy case.\u001B[39;00m\n\u001B[1;32m--> 262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlegacy_sm_saving_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    264\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\saving\\legacy\\save.py:233\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, options)\u001B[0m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(filepath_str, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    232\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mexists(filepath_str):\n\u001B[1;32m--> 233\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\n\u001B[0;32m    234\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo file or directory found at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    235\u001B[0m         )\n\u001B[0;32m    237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39misdir(filepath_str):\n\u001B[0;32m    238\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m saved_model_load\u001B[38;5;241m.\u001B[39mload(\n\u001B[0;32m    239\u001B[0m             filepath_str, \u001B[38;5;28mcompile\u001B[39m, options\n\u001B[0;32m    240\u001B[0m         )\n",
      "\u001B[1;31mOSError\u001B[0m: No file or directory found at model_experiments/flowers_resnet50"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_2 = pd.read_csv(UNSTRUCTURED_METRICS)\n",
    "plot_unstructured_accuracy_sparcity(data_2)"
   ],
   "id": "684c4a1d55fafeb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Final Model Pruning",
   "id": "a056e6635a83c0a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:45:24.948060Z",
     "start_time": "2024-12-18T19:45:24.891559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_2 = models.load_model(\"model_experiments/flowers_resnet50.keras\")\n",
    "\n",
    "final_sparsity = 0.7\n",
    "\n",
    "pruned_model_final = unstructured_prune_model(model_1, final_sparsity, 20,data_training, data_validation, BATCH_SIZE)\n",
    "\n",
    "final_pruned_model = pruned_model_final.model\n",
    "\n",
    "final_pruned_model.save(FLOWERS_MODEL + \"_pruned_\" + str(final_sparsity) + \".keras\")\n",
    "final_pruned_model.summary()"
   ],
   "id": "91337e9aaf2388b9",
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at model_experiments/flowers_resnet50.keras",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model_2 \u001B[38;5;241m=\u001B[39m \u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel_experiments/flowers_resnet50.keras\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m final_sparsity \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.7\u001B[39m\n\u001B[0;32m      5\u001B[0m pruned_model_final \u001B[38;5;241m=\u001B[39m unstructured_prune_model(model_1, final_sparsity, \u001B[38;5;241m20\u001B[39m,data_training, data_validation, BATCH_SIZE)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\saving\\saving_api.py:262\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001B[0m\n\u001B[0;32m    254\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[0;32m    255\u001B[0m         filepath,\n\u001B[0;32m    256\u001B[0m         custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects,\n\u001B[0;32m    257\u001B[0m         \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m,\n\u001B[0;32m    258\u001B[0m         safe_mode\u001B[38;5;241m=\u001B[39msafe_mode,\n\u001B[0;32m    259\u001B[0m     )\n\u001B[0;32m    261\u001B[0m \u001B[38;5;66;03m# Legacy case.\u001B[39;00m\n\u001B[1;32m--> 262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlegacy_sm_saving_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    264\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\saving\\legacy\\save.py:233\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, options)\u001B[0m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(filepath_str, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    232\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mexists(filepath_str):\n\u001B[1;32m--> 233\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\n\u001B[0;32m    234\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo file or directory found at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    235\u001B[0m         )\n\u001B[0;32m    237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39misdir(filepath_str):\n\u001B[0;32m    238\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m saved_model_load\u001B[38;5;241m.\u001B[39mload(\n\u001B[0;32m    239\u001B[0m             filepath_str, \u001B[38;5;28mcompile\u001B[39m, options\n\u001B[0;32m    240\u001B[0m         )\n",
      "\u001B[1;31mOSError\u001B[0m: No file or directory found at model_experiments/flowers_resnet50.keras"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pruning the model with entropy",
   "id": "c182e37e2cc67113"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_threshold = 0.028\n",
    "final_model = models.load_model(\"model_experiments/flowers_resnet50.kera\")\n",
    "entropy = EntropyPruningSurgeon(model=final_model, threshold=test_threshold)\n",
    "pruned_model = entropy.run()\n",
    "pruned_model.summary()"
   ],
   "id": "1ab440da12259cf9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pruning the model with L1- Norm",
   "id": "76cbb8c720b0ba45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "k_l1_norm = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.4, 0.5]\n",
    "metric_list = []\n",
    "\n",
    "for k in k_l1_norm:\n",
    "    model_1 = models.load_model(\"model_experiments/custom_vgg16.keras\")\n",
    "    pruned_model: PrunedModel = l1_norm_prune_model(model_1,20,k,train_batches,validation_batches,BATCH_SIZE)\n",
    "    metrics = pruned_model.metrics\n",
    "    val_loss = metrics[\"val_loss\"]\n",
    "    val_accuracy = metrics[\"val_accuracy\"]\n",
    "    print(f\"L1_norm_threshold={k}, \\t {val_loss=}, \\t {val_accuracy=}\")\n",
    "    metric_list.append(metrics)\n",
    "\n",
    "# Create a dataframe of the values obtained\n",
    "df = pd.DataFrame(metric_list)\n",
    "df.to_csv(L1_NORM_METRICS)\n",
    "df"
   ],
   "id": "86bbab0da67286ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Apply a compression algorithm to see the benefits of pruning",
   "id": "2a5566c8026e3ed9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(final_pruned_model)\n",
    "model_for_export.save_weights(UNSTRUCTURED_FLOWERS_WEIGHTS)\n",
    "model_for_export.summary()"
   ],
   "id": "77973c6f32e94681"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Need to convert the model to a TFLite model",
   "id": "1c32a63433294462"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T19:50:08.727549Z",
     "start_time": "2024-12-18T19:50:08.701620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "    f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)"
   ],
   "id": "73256c71de90a9cb",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_for_export' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m converter \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mlite\u001B[38;5;241m.\u001B[39mTFLiteConverter\u001B[38;5;241m.\u001B[39mfrom_keras_model(\u001B[43mmodel_for_export\u001B[49m)\n\u001B[0;32m      2\u001B[0m pruned_tflite_model \u001B[38;5;241m=\u001B[39m converter\u001B[38;5;241m.\u001B[39mconvert()\n\u001B[0;32m      4\u001B[0m _, pruned_tflite_file \u001B[38;5;241m=\u001B[39m tempfile\u001B[38;5;241m.\u001B[39mmkstemp(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.tflite\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model_for_export' is not defined"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Apply the Quantization algorithm to the model",
   "id": "a69e8356c1fe8bac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "    f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)"
   ],
   "id": "7c637595fc55301c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
