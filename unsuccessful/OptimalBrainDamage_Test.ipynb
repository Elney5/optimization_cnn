{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-02T03:17:04.978814Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\"\n",
    "from tf_keras import losses,optimizers\n",
    "from tf_keras import models\n",
    "import importlib"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T22:07:19.459761Z",
     "start_time": "2024-11-30T22:07:16.113943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.load_dataset import load_dataset\n",
    "train_examples, validation_examples, num_examples, num_classes, class_names = load_dataset('horses_or_humans', 70)"
   ],
   "id": "ecb8ea3908f951ee",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T22:07:20.629807Z",
     "start_time": "2024-11-30T22:07:20.522898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.reformat_image import reformat_image\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "train_batches = train_examples.cache().shuffle(num_examples // 4).map(reformat_image).batch(BATCH_SIZE).prefetch(1)\n",
    "validation_batches = validation_examples.map(reformat_image).batch(BATCH_SIZE).prefetch(1)\n",
    "train_batches"
   ],
   "id": "fc13ace32ba67ec7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T02:05:36.404955Z",
     "start_time": "2024-12-01T02:01:40.511482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from unsuccessful import OptimalBrainDamage\n",
    "\n",
    "importlib.reload(OptimalBrainDamage)\n",
    "from unsuccessful.OptimalBrainDamage import OptimalBrainDamage\n",
    "model_SBD = models.load_model(\"../model_experiments/custom_vgg16.keras\")\n",
    "\n",
    "pruning = OptimalBrainDamage(model=model_SBD, sparsity=0.3)\n",
    "\n",
    "# Générer des cibles (étiquettes) dans la plage [0, 1] pour 2 classes\n",
    "targets = tf.random.uniform((1,), minval=0, maxval=2, dtype=tf.int32)\n",
    "\n",
    "# Générer une entrée d'image aléatoire\n",
    "inputs = tf.random.normal((1, 224, 224, 3))  # Exemple d'entrée (1 image, 224x224x3)\n",
    "\n",
    "# Calculer la perte à l'intérieur de tf.GradientTape\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(model_SBD.trainable_variables)  # Assurez-vous de regarder les variables du modèle\n",
    "    predictions = model_SBD(inputs)  # Passer les inputs dans le modèle\n",
    "    print(predictions)\n",
    "    loss = losses.SparseCategoricalCrossentropy()(targets, predictions)  # Calculer la perte avec les targets\n",
    "\n",
    "# Calculer les gradients\n",
    "gradients = tape.gradient(loss, model_SBD.trainable_variables)\n",
    "\n",
    "\n",
    "pruningmodel = pruning.run(inputs, targets)\n",
    "pruningmodel.summary()"
   ],
   "id": "97b650596b1c82c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.28264362 0.7173563 ]], shape=(1, 2), dtype=float32)\n",
      "Calcul de la Hessienne...\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node loop_body/AddN_2/pfor/AddN/tmp_var_zeros defined at (most recent call last):\n<stack traces unavailable>\nCannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 150528\n  }\n  dim {\n    size: 1\n  }\n  dim {\n    size: 14\n  }\n  dim {\n    size: 14\n  }\n  dim {\n    size: 512\n  }\n}\n\n\t [[{{node loop_body/AddN_2/pfor/AddN/tmp_var_zeros}}]] [Op:__inference_get_hessian_127160]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[56], line 25\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# Calculer les gradients\u001B[39;00m\n\u001B[0;32m     22\u001B[0m gradients \u001B[38;5;241m=\u001B[39m tape\u001B[38;5;241m.\u001B[39mgradient(loss, model_SBD\u001B[38;5;241m.\u001B[39mtrainable_variables)\n\u001B[1;32m---> 25\u001B[0m pruningmodel \u001B[38;5;241m=\u001B[39m \u001B[43mpruning\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m pruningmodel\u001B[38;5;241m.\u001B[39msummary()\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\OptimalBrainDamage.py:87\u001B[0m, in \u001B[0;36mOptimalBrainDamage.run\u001B[1;34m(self, inputs, targets)\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;66;03m# Calculer la Hessienne\u001B[39;00m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCalcul de la Hessienne...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 87\u001B[0m hessian \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_hessian\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;66;03m# Pruner les poids\u001B[39;00m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPruning des poids...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     54\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node loop_body/AddN_2/pfor/AddN/tmp_var_zeros defined at (most recent call last):\n<stack traces unavailable>\nCannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 150528\n  }\n  dim {\n    size: 1\n  }\n  dim {\n    size: 14\n  }\n  dim {\n    size: 14\n  }\n  dim {\n    size: 512\n  }\n}\n\n\t [[{{node loop_body/AddN_2/pfor/AddN/tmp_var_zeros}}]] [Op:__inference_get_hessian_127160]"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pruningmodel.compile(loss=losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=['accuracy'])"
   ],
   "id": "222f2e2c61b28be4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
