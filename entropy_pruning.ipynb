{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Entropy pruning\n",
    "\n",
    "## IMPORTS"
   ],
   "id": "e26b194d50bea1ad"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T23:53:17.968747Z",
     "start_time": "2024-12-01T23:53:03.561358Z"
    }
   },
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from configparser import ConfigParser\n",
    "\n",
    "\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\"\n",
    "\n",
    "from tf_keras import losses,optimizers, models\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "from utils import load_dataset, reformat_image, entropy_prune_model\n",
    "from utils.Objects import EntropyPruningSurgeon, PrunedModel\n",
    "from utils.Plots import plot_unstructured_accuracy_sparcity"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## CONSTANTS"
   ],
   "id": "90f56d54e8c4d02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T23:53:17.983435Z",
     "start_time": "2024-12-01T23:53:17.975770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "BATCH_SIZE = int(config[\"BATCHES\"][\"BATCH_SIZE\"])\n",
    "\n",
    "IMG_SIZE = (int(config[\"IMAGES\"][\"IMG_SIZE\"]), int(config[\"IMAGES\"][\"IMG_SIZE\"]))\n",
    "\n",
    "MODEL_DIRECTORY = config[\"MODEL\"][\"MODEL_DIRECTORY\"]\n",
    "METRICS_DIRECTORY = config[\"MODEL\"][\"METRICS_DIRECTORY\"]\n",
    "ENTROPY_METRICS = os.path.join(METRICS_DIRECTORY, config[\"MODEL\"][\"ENTROPY_METRICS\"])\n",
    "HORSE_AND_HUMAN_MODEL = os.path.join(MODEL_DIRECTORY, config[\"MODEL\"][\"HORSE_AND_HUMAN_MODEL\"])"
   ],
   "id": "aa2228bfebddf148",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T23:53:19.712880Z",
     "start_time": "2024-12-01T23:53:18.506956Z"
    }
   },
   "cell_type": "code",
   "source": "train_examples, validation_examples, num_examples, num_classes, class_names = load_dataset('horses_or_humans', 70)",
   "id": "3dfca37d679c6ef0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from C:\\Users\\neyen\\tensorflow_datasets\\horses_or_humans\\3.0.0\n",
      "INFO:absl:Creating a tf.data.Dataset reading 2 files located in folders: C:\\Users\\neyen\\tensorflow_datasets\\horses_or_humans\\3.0.0.\n",
      "INFO:absl:Creating a tf.data.Dataset reading 1 files located in folders: C:\\Users\\neyen\\tensorflow_datasets\\horses_or_humans\\3.0.0.\n",
      "INFO:absl:Constructing tf.data.Dataset horses_or_humans for split ('train[:70%]', 'train[70%:]'), from C:\\Users\\neyen\\tensorflow_datasets\\horses_or_humans\\3.0.0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T23:53:19.834780Z",
     "start_time": "2024-12-01T23:53:19.752762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_batches = train_examples.cache().shuffle(num_examples // 4).map(reformat_image).batch(BATCH_SIZE).prefetch(1)\n",
    "validation_batches = validation_examples.map(reformat_image).batch(BATCH_SIZE).prefetch(1)"
   ],
   "id": "cdc250b3c14c9cb1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T23:53:23.557212Z",
     "start_time": "2024-12-01T23:53:19.853557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "testt_model = models.load_model(\"model_experiments/custom_vgg16.keras\")\n",
    "pruning = EntropyPruningSurgeon(model=testt_model, threshold=0.3)\n",
    "pruningmodel = pruning.run()\n",
    "pruningmodel.summary()"
   ],
   "id": "6db2bde71aab52b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\saving\\legacy\\saved_model\\load.py:109: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\saving\\legacy\\saved_model\\load.py:109: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\engine\\functional.py:156: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\engine\\functional.py:156: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting 63/64 channels from layer: block1_conv1\n",
      "Deleting 63/64 channels from layer: block1_conv2\n",
      "Deleting 127/128 channels from layer: block2_conv1\n",
      "Deleting 127/128 channels from layer: block2_conv2\n",
      "Deleting 255/256 channels from layer: block3_conv1\n",
      "Deleting 255/256 channels from layer: block3_conv2\n",
      "Deleting 255/256 channels from layer: block3_conv3\n",
      "Deleting 511/512 channels from layer: block4_conv1\n",
      "Deleting 511/512 channels from layer: block4_conv2\n",
      "Deleting 511/512 channels from layer: block4_conv3\n",
      "Deleting 511/512 channels from layer: block5_conv1\n",
      "Deleting 511/512 channels from layer: block5_conv2\n",
      "Deleting 511/512 channels from layer: block5_conv3\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " input_40 (InputLayer)       multiple                  0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 1)       28        \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 1)       10        \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  multiple                  0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 1)       10        \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 1)       10        \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  multiple                  0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 1)         10        \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 1)         10        \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 1)         10        \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  multiple                  0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 1)         10        \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 1)         10        \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 1)         10        \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  multiple                  0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 1)         10        \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 1)         10        \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 1)         10        \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  multiple                  0         \n",
      "                                                                 \n",
      " global_max_pool (GlobalMax  multiple                  0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 2)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 152 (608.00 Byte)\n",
      "Trainable params: 4 (16.00 Byte)\n",
      "Non-trainable params: 148 (592.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T23:53:25.406973Z",
     "start_time": "2024-12-01T23:53:23.851341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the model\n",
    "pruningmodel.compile(loss=losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer = optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "pruningmodel.evaluate(validation_batches)"
   ],
   "id": "cf7369ddf137dde1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neyen\\Documents\\Pro\\Projet\\tf1\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 35ms/step - loss: 0.6949 - accuracy: 0.4838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6948645114898682, 0.48376622796058655]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Choose the best entropy level\n",
    "k_entropies = np.arange(0.019, 0.029, 0.001)\n",
    "metric_list = []\n",
    "\n",
    "for k in k_entropies:\n",
    "    # Load in the best saved model\n",
    "    model_1 = models.load_model(HORSE_AND_HUMAN_MODEL + \".keras\")\n",
    "    pruned_model: PrunedModel = entropy_prune_model(model_1, 20, k, train_batches, validation_batches, BATCH_SIZE)\n",
    "    metrics = pruned_model.metrics\n",
    "    val_loss = metrics[\"val_loss\"]\n",
    "    val_accuracy = metrics[\"val_accuracy\"]\n",
    "\n",
    "    print(f\"Entropy={k}, \\t {val_loss=}, \\t {val_accuracy=}\")\n",
    "    metric_list.append(metrics)\n",
    "\n",
    "# Create a dataframe of the values obtained\n",
    "df = pd.DataFrame(metric_list)\n",
    "df.to_csv(ENTROPY_METRICS)\n",
    "df"
   ],
   "id": "b58a8495f4cc4ce4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = pd.read_csv(ENTROPY_METRICS)\n",
    "plot_unstructured_accuracy_sparcity(data)"
   ],
   "id": "7c271945ba597bea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T23:53:25.464022500Z",
     "start_time": "2024-11-26T18:31:40.682077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ],
   "id": "e6302f2afcdb5cfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neyen\\AppData\\Local\\Temp\\ipykernel_71452\\369930696.py:4: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: C:\\Users\\neyen\\AppData\\Local\\Temp\\tmpjh1lij65.h5\n"
     ]
    }
   ],
   "execution_count": 196
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
